# Fusion-AI---MultiModal-Persuvasiveness-Prediction
 Developed a multi-modal AI system to predict the persuasiveness of content by analyzing and fusing data from text, images, and audio.
 
 Employed BERT for text embeddings, ResNet for image feature extraction, and Librosa for audio analysis, combining these modalities for robust predictions.

 Implemented fusion techniques to integrate features from multiple data sources, enhancing the modelâ€™s ability to assess the overall persuasiveness of multimedia content.
 
 Fine-tuned the model for performance using machine learning techniques, achieving high accuracy in persuasiveness classification. 
 
 Built the system using Python, leveraging libraries like PyTorch, TensorFlow, and OpenCV for end-to-end deployment.
